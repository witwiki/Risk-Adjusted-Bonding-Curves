{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Properties and Validation Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The risk-adjusted bonding curve system requires certain properties to be considered a good estimator of project risk and token price. We also require that it is a fair system, where agents are rewarded according to how accurately they predict the project's future success. \n",
    "\n",
    "To validate that these properties are indeed present in the modeled system, we conduct validation tests for the following: <br/>\n",
    "**1. Convergence of Alpha** <br/>\n",
    "**2. Convergence of Price** <br/>\n",
    "**3. Empirically demonstrate correlation of agents' payouts to their beliefs**\n",
    "\n",
    "Each validation test is a controlled experiment performed in an environment set up to most clearly and obviously reveal the system property or behaviour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convergence of Alpha\n",
    "\n",
    "### Introduction\n",
    "The Prediction Market in the risk-adjusted bonding curve system acts as an estimator for Alpha, the likelihood of project success.\n",
    "\n",
    "$$ \\alpha \\in [0,1] $$\n",
    "where $\\alpha = 0$ indicates that the project is estimated to fail, and $\\alpha = 1$ indicates the highest likelhood of project success. Refer [Mathematical Model of a Risk-Adjusted Bonding Curve](Math_Specification/1_System_Specification.ipynb) for context.\n",
    "\n",
    "### Hypothesis\n",
    "Alpha converges to a stable value based on agents' positive and negative attestations on project success. \n",
    " \n",
    "### Experiment set up\n",
    "We set up a 2-agent system. Each agent is initialized with two extreme private beliefs of Alpha. <br/>\n",
    "Agent 1's private belief of Alpha = 0.1 <br/>\n",
    "Agent 2's private belief of Alpha = 0.9\n",
    "\n",
    "The agents maintain this private belief of Alpha throughout the system execution.\n",
    "\n",
    "All other agent parameters are initalized as equivalent for both agents. They start out with the same private belief of Price, the same amount of supply tokens, and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "                  ___________    ____\n",
      "  ________ __ ___/ / ____/   |  / __ \\\n",
      " / ___/ __` / __  / /   / /| | / / / /\n",
      "/ /__/ /_/ / /_/ / /___/ ___ |/ /_/ /\n",
      "\\___/\\__,_/\\__,_/\\____/_/  |_/_____/\n",
      "by cadCAD\n",
      "\n",
      "Execution Mode: multi_proc\n",
      "Configuration Count: 1\n",
      "Dimensions of the first simulation: (Timesteps, Params, Runs, Vars) = (500, 20, 3, 19)\n",
      "Execution Method: parallelize_simulations\n",
      "Execution Mode: parallelized\n",
      "Total execution time: 10.63s\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'sim_id_records' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7014f696aaa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"whitegrid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mexperiments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\vicku\\Documents\\GitHub\\Risk-Adjusted-Bonding-Curves\\src\\sim\\run.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(drop_midsteps, df)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mmod_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'sim_id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msim_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'meta'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresult_record\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0msim_id\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msim_id_records\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0msim_id_records\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mresult_records_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod_record\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sim_id_records' is not defined"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append('../')\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import run2\n",
    "\n",
    "from src.sim import run\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# For analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "experiments = run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.sort_values(by =['rules_price']).reset_index(drop=True)\n",
    "\n",
    "cols = 1\n",
    "rows = 1\n",
    "cc_idx = 0\n",
    "\n",
    "\n",
    "while cc_idx<len(experiments):\n",
    "    cc = experiments.iloc[cc_idx]['rules_price']\n",
    "    cc_label = experiments.iloc[cc_idx]['rules_price']\n",
    "#     secondary_label = experiments.iloc[cc_idx]['string']\n",
    "    sub_experiments = experiments[experiments['rules_price']==cc]\n",
    "    cc_idx += len(sub_experiments)\n",
    "    fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(15*cols,7*rows))\n",
    "    sub_experiments.reset_index(drop=False)\n",
    "    for i, experiment in sub_experiments.iterrows():\n",
    "        df = experiment['dataset'].copy()\n",
    "        # filter out starting point\n",
    "        df = df[df.timestep > 0] \n",
    "        # FIRST RUN ONLY\n",
    "        df = df[df.run == 1]  \n",
    "\n",
    "# MAKE A FOR LOOP or FUNCTION FOR ALL AGENTS\n",
    "        chosen_agents = df['chosen_agent'].tolist()\n",
    "        chosen_agents_private_alphas = []\n",
    "        for agent in chosen_agents:\n",
    "            chosen_agents_private_alphas.append(agent['agent_private_alpha'])\n",
    "        \n",
    "        df['private_alpha'] = chosen_agents_private_alphas\n",
    "            \n",
    "        df['agent_1_private_alpha'] = df.agents.apply(lambda x: np.array(x['agent_private_alpha'][0]))\n",
    "        df['agent_2_private_alpha'] = df.agents.apply(lambda x: np.array(x['agent_private_alpha'][1]))\n",
    "        \n",
    "\n",
    "        plot_label = experiment['rules_price']\n",
    "        ax = axs\n",
    "        title = 'Agent Private Alpha vs Global Alpha' + '\\n' \n",
    "        # + 'Scenario: ' + str(cc_label)  + ' rules_price'\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel('Alpha Value')\n",
    "        colors = ['b','orange', 'g', 'magenta', 'r', 'k' ]\n",
    "        \n",
    "        plt.hlines(y= max(df['agent_1_private_alpha']), xmin=0, xmax=max(df.timestep), label = 'Agent 1 Private Alpha',  color = colors[0])\n",
    "        plt.hlines(y= max(df['agent_2_private_alpha']), xmin=0, xmax=max(df.timestep), label = 'Agent 2 Private Alpha',  color = colors[1])\n",
    "\n",
    "        df.plot(x='timestep', y='private_alpha', label='Private Alpha', ax=ax, legend=True, kind= 'scatter')\n",
    "        df.plot(x='timestep', y='alpha', label='Alpha', ax=ax, legend=True, color = colors[5])\n",
    "\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        ax.set_xlabel('Timesteps')\n",
    "        ax.grid(color='0.9', linestyle='-', linewidth=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "fig.tight_layout(rect=[0, 0, 1, .97])\n",
    "fig.patch.set_alpha(1)\n",
    "display(fig)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha converges as the agents make attestations over time. \n",
    "\n",
    "The system responds well to the agents' attestations, incorporating each attestation into the estimation of system Alpha. We conclude that the system is a good estimator of likelihood of project success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convergence of Price\n",
    "\n",
    "### Introduction\n",
    "The Bonding Curve in the risk-adjusted bonding curve system acts as an estimator for the Price of the system's supply token.\n",
    "$$ P = \\kappa \\frac{R}{S}\\space\\space\\space ; \\space\\space\\space P \\in [0,\\infty)$$\n",
    "Refer [Mathematical Model of a Risk-Adjusted Bonding Curve](Math_Specification/1_System_Specification.ipynb) for context.\n",
    "\n",
    "### Hypothesis\n",
    "Price converges to a stable value based on agents' bond actions to obtain supply tokens and burn actions to sell their supply tokens. \n",
    " \n",
    "### Experiment set up\n",
    "We set up a 2-agent system. Each agent is initialized with two extreme private beliefs of Price. <br/>\n",
    "Agent 1's private belief of Price = 0.2 <br/>\n",
    "Agent 2's private belief of Price = 2\n",
    "\n",
    "The agents maintain this private belief of Price throughout the system execution.\n",
    "\n",
    "They start out with the different private beliefs of Alpha. All other variables are equivalent, such as the same amount of supply tokens, and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.sort_values(by =['rules_price']).reset_index(drop=True)\n",
    "\n",
    "cols = 1\n",
    "rows = 1\n",
    "cc_idx = 0\n",
    "\n",
    "\n",
    "while cc_idx<len(experiments):\n",
    "    cc = experiments.iloc[cc_idx]['rules_price']\n",
    "    cc_label = experiments.iloc[cc_idx]['rules_price']\n",
    "#     secondary_label = experiments.iloc[cc_idx]['string']\n",
    "    sub_experiments = experiments[experiments['rules_price']==cc]\n",
    "    cc_idx += len(sub_experiments)\n",
    "    fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(15*cols,7*rows))\n",
    "    sub_experiments.reset_index(drop=False)\n",
    "    for i, experiment in sub_experiments.iterrows():\n",
    "        df = experiment['dataset'].copy()\n",
    "        # filter out starting point\n",
    "        df = df[df.timestep > 0] \n",
    "        # FIRST RUN ONLY\n",
    "        df = df[df.run == 1]  \n",
    "\n",
    "# MAKE A FOR LOOP or FUNCTION FOR ALL AGENTS\n",
    "        chosen_agents = df['chosen_agent'].tolist()\n",
    "        chosen_agents_private_prices = []\n",
    "        for agent in chosen_agents:\n",
    "            chosen_agents_private_prices.append(agent['agent_private_price'])\n",
    "        \n",
    "        df['private_price'] = chosen_agents_private_prices\n",
    "            \n",
    "        df['agent_1_private_price'] = df.agents.apply(lambda x: np.array(x['agent_private_price'][0]))\n",
    "        df['agent_2_private_price'] = df.agents.apply(lambda x: np.array(x['agent_private_price'][1]))\n",
    "        \n",
    "\n",
    "        plot_label = experiment['rules_price']\n",
    "        ax = axs\n",
    "        title = 'Agent Private Price vs Global Price' \n",
    "        # + '\\n' + 'Scenario: ' + str(cc_label)  + ' rules_price'\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel('Price')\n",
    "        colors = ['b','orange', 'g', 'magenta', 'r', 'k' ]\n",
    "        \n",
    "        plt.hlines(y= max(df['agent_1_private_price']), xmin=0, xmax=max(df.timestep), label = 'Agent 1 Private Price',  color = colors[0])\n",
    "        plt.hlines(y= max(df['agent_2_private_price']), xmin=0, xmax=max(df.timestep), label = 'Agent 2 Private Price',  color = colors[1])\n",
    "\n",
    "        df.plot(x='timestep', y='private_price', label='Private Price at action', ax=ax, legend=True, kind= 'scatter')\n",
    "        df.plot(x='timestep', y='spot_price', label='Price', ax=ax, legend=True, color = colors[5])\n",
    "\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        ax.set_xlabel('Timesteps')\n",
    "        ax.grid(color='0.9', linestyle='-', linewidth=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "fig.tight_layout(rect=[0, 0, 1, .97])\n",
    "fig.patch.set_alpha(1)\n",
    "display(fig)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference \n",
    "\n",
    "Price converges as the agents bond and burn tokens over time. \n",
    "\n",
    "The system responds well to the agents' bond and burn actions, incorporating each action into the estimation of system Price. We conclude that the system is a good estimator of the token price.\n",
    "\n",
    "The plots below show how system Reserve and system Supply change as agents bond or burn tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.sort_values(by =['rules_price']).reset_index(drop=True)\n",
    "\n",
    "cols = 1\n",
    "rows = 1\n",
    "cc_idx = 0\n",
    "# config_labels = ['RULE 1,'RULE 2']\n",
    "\n",
    "\n",
    "while cc_idx<len(experiments):\n",
    "    cc = experiments.iloc[cc_idx]['rules_price']\n",
    "    cc_label = experiments.iloc[cc_idx]['rules_price']\n",
    "#     secondary_label = experiments.iloc[cc_idx]['string']\n",
    "    sub_experiments = experiments[experiments['rules_price']==cc]\n",
    "    cc_idx += len(sub_experiments)\n",
    "    fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(15*cols,7*rows))\n",
    "    sub_experiments.reset_index(drop=False)\n",
    "    for i, experiment in sub_experiments.iterrows():\n",
    "        df = experiment['dataset'].copy()\n",
    "        # filter out starting point\n",
    "        df = df[df.timestep > 0] \n",
    "        # FIRST RUN ONLY\n",
    "#         df = df[df.run == 1]  \n",
    "        \n",
    "        df = df.groupby('timestep').agg({'reserve': ['min', 'mean', 'max']}).reset_index()\n",
    "\n",
    "        plot_label = experiment['rules_price']\n",
    "        ax = axs\n",
    "        title = 'Reserve' + '\\n' + 'Scenario: ' \n",
    "        #+ str(cc_label)  + ' rules_price'\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel('Alpha Value')\n",
    "        colors = ['b','orange', 'g', 'magenta', 'r', 'k' ]\n",
    "\n",
    "        ax.plot(df.timestep, df[('reserve','mean')],label='reserve') \n",
    "\n",
    "        ax.fill_between(df.timestep, df[('reserve','min')], df[('reserve','max')])#, supply=0.3) \n",
    "\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        ax.set_xlabel('Timesteps')\n",
    "        ax.grid(color='0.9', linestyle='-', linewidth=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "fig.tight_layout(rect=[0, 0, 1, .97])\n",
    "fig.patch.set_alpha(1)\n",
    "display(fig)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.sort_values(by =['rules_price']).reset_index(drop=True)\n",
    "\n",
    "cols = 1\n",
    "rows = 1\n",
    "cc_idx = 0\n",
    "# config_labels = ['RULE 1,'RULE 2']\n",
    "\n",
    "\n",
    "while cc_idx<len(experiments):\n",
    "    cc = experiments.iloc[cc_idx]['rules_price']\n",
    "    cc_label = experiments.iloc[cc_idx]['rules_price']\n",
    "#     secondary_label = experiments.iloc[cc_idx]['string']\n",
    "    sub_experiments = experiments[experiments['rules_price']==cc]\n",
    "    cc_idx += len(sub_experiments)\n",
    "    fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(15*cols,7*rows))\n",
    "    sub_experiments.reset_index(drop=False)\n",
    "    for i, experiment in sub_experiments.iterrows():\n",
    "        df = experiment['dataset'].copy()\n",
    "        # filter out starting point\n",
    "        df = df[df.timestep > 0] \n",
    "        # FIRST RUN ONLY\n",
    "#         df = df[df.run == 1]  \n",
    "        \n",
    "        df = df.groupby('timestep').agg({'supply': ['min', 'mean', 'max']}).reset_index()\n",
    "\n",
    "        plot_label = experiment['rules_price']\n",
    "        ax = axs\n",
    "        title = 'Supply' + '\\n' + 'Scenario: ' \n",
    "        #+ str(cc_label)  + ' rules_price'\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel('Alpha Value')\n",
    "        colors = ['b','orange', 'g', 'magenta', 'r', 'k' ]\n",
    "\n",
    "        ax.plot(df.timestep, df[('supply','mean')],label='supply') \n",
    "\n",
    "        ax.fill_between(df.timestep, df[('supply','min')], df[('supply','max')])#, supply=0.3) \n",
    "\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        ax.set_xlabel('Timesteps')\n",
    "        ax.grid(color='0.9', linestyle='-', linewidth=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "fig.tight_layout(rect=[0, 0, 1, .97])\n",
    "fig.patch.set_alpha(1)\n",
    "display(fig)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation of agents' payouts to their beliefs\n",
    "\n",
    "### Introduction\n",
    "Agents take actions based on their private beilef of Alpha and Price. If they believe Alpha is higher than the current system Alpha, then they will make a positive attestation and vice versa. Likewise, if an agent believes the price to be higher than the current system price, they will make a bond action and vice versa.\n",
    "For more information on agent behaviour heuristics, see [AgentBehaviourModel - Heuristic](Math_Specification/4a_AgentBehaviourModel - Heuristic.ipynb)\n",
    "\n",
    "Agents participate in the prediction market motivated by the ability to increase their final payout once the bond has completed its execution. An agent with $n$ supply tokens can choose to keep the tokens as is (as $s_{free}$), or use them to make positive attestations ($s_1$) or negative attestations ($s_0$) in the hope of increasing their expected future payout.\n",
    "\n",
    "The payout $\\Theta_a$ of an agent comprises of their share of payout corresponding to their holdings of $s_{free}$, $s_1$ and $s_0$. \n",
    "$$\\Theta_a = \\frac{s_{free}}{s} (\\alpha_t C+R) + \\alpha_t \\frac{q_1}{Q_1} \\frac{s_1}{s} (C+R) + (1-\\alpha_t) \\frac{q_0}{Q_0} \\frac{s_0}{s} (R)$$\n",
    "\n",
    "### Hypothesis\n",
    "The agent that has the closest prediction of final system Alpha - i.e. their private belief of Alpha - obtains the largest final payout.\n",
    " \n",
    "### Experiment set up\n",
    "We set up a 21-agent system. Each agent is initialized with equidistant private beliefs of Alpha. <br/>\n",
    "Agent 1's private belief of Alpha = 0.00 <br/>\n",
    "Agent 2's private belief of Alpha = 0.05 <br/>\n",
    "Agent 3's private belief of Alpha = 0.10 <br/>\n",
    ". . . <br/>\n",
    "Agent 21's private belief of Alpha = 1.0 <br/>\n",
    "\n",
    "All agents have the same private belief of Price, which remains constant throughout the system execution.\n",
    "\n",
    "Other agent parameters are initialized equally for all agents. They start out with the same reserve as well as same amount of supply tokens in all pools, with initial values as the following:\n",
    "\n",
    "\n",
    "| Agent Variable Name -> | agent_attestations_1 | agent_attestations_0 | agent_reserve | agent_supply_1 | agent_supply_0 | agent_supply_free |\n",
    "|:-----------------------|:--------------------:|:--------------------:|:--------------------:|:--------------------:|:--------------------:|:-------------:|\n",
    "|Brief Description ->    | Claim on Pos. Attest. | Claim on Neg. Attest. | Reserve funds | Pos. Attest Tokens |  Neg. Attest Tokens  |  Unattested Tokens  |\n",
    "|Initial Value ->        | 0  | 0 | 100   | 3 | 3 | 44 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents vs their Positive Attestations\n",
    "#### The table below is a snapshot at one timeslice during the simulation of the all of the agents current positions. We observe that agents with low beliefs of alpha have attested negatively (agent_attestations_0). Agents with alpha beliefs closer to 1 have only attested positively (agent_attestations_1). Importantly, agents within the range of alphas and their own threshold values during the simulation (alpha = 0.5 and 0.55) have attested both positively and negatively.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1601\n",
    "\n",
    "experiments.dataset[0].agents[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.sort_values(by =['rules_price']).reset_index(drop=True)\n",
    "\n",
    "cols = 1\n",
    "rows = 1\n",
    "cc_idx = 0\n",
    "# config_labels = ['RULE 1,'RULE 2']\n",
    "\n",
    "\n",
    "while cc_idx<len(experiments):\n",
    "    cc = experiments.iloc[cc_idx]['rules_price']\n",
    "    cc_label = experiments.iloc[cc_idx]['rules_price']\n",
    "    sub_experiments = experiments[experiments['rules_price']==cc]\n",
    "    cc_idx += len(sub_experiments)\n",
    "    fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(15*cols,7*rows))\n",
    "    sub_experiments.reset_index(drop=False)\n",
    "    for i, experiment in sub_experiments.iterrows():\n",
    "        df = experiment['dataset'].copy()\n",
    "        # filter out starting point\n",
    "        df = df[df.timestep > 0] \n",
    "        # FIRST RUN ONLY\n",
    "        df = df[df.run == 1]  \n",
    "        \n",
    "\n",
    "# MAKE A FOR LOOP or FUNCTION FOR ALL AGENTS\n",
    "        df['agent_1_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][0]))\n",
    "        df['agent_2_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][1]))\n",
    "        df['agent_3_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][2]))\n",
    "        df['agent_4_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][3]))\n",
    "        df['agent_5_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][4]))\n",
    "        df['agent_6_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][5]))\n",
    "        df['agent_7_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][6]))\n",
    "        df['agent_8_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][7]))\n",
    "        df['agent_9_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][8]))\n",
    "        df['agent_10_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][9]))\n",
    "        df['agent_11_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][10]))\n",
    "        df['agent_12_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][11]))\n",
    "        df['agent_13_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][12]))\n",
    "        df['agent_14_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][13]))\n",
    "        df['agent_15_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][14]))\n",
    "        df['agent_16_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][15]))\n",
    "        df['agent_17_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][16]))\n",
    "        df['agent_18_attest_1'] = df.agents.apply(lambda x: np.array(x['agent_attestations_1'][17]))\n",
    "\n",
    "        plot_label = experiment['rules_price']\n",
    "        ax = axs\n",
    "        title = 'Agents vs. their Positive Attestations' + '\\n' \n",
    "        # + 'Scenario: ' + str(cc_label)  + ' rules_price'\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel('Amount')\n",
    "        colors = ['b','orange', 'g', 'magenta', 'r']\n",
    "\n",
    "        df.plot(x='timestep', y='agent_1_attest_1', label='agent_1', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_2_attest_1', label='agent_2', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_3_attest_1', label='agent_3', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_4_attest_1', label='agent_4', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_5_attest_1', label='agent_5', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_6_attest_1', label='agent_6', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_7_attest_1', label='agent_7', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_8_attest_1', label='agent_8', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_9_attest_1', label='agent_9', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_10_attest_1', label='agent_10', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_11_attest_1', label='agent_11', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_12_attest_1', label='agent_12', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_13_attest_1', label='agent_13', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_14_attest_1', label='agent_14', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_15_attest_1', label='agent_15', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_16_attest_1', label='agent_16', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_17_attest_1', label='agent_17', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_18_attest_1', label='agent_18', ax=ax, legend=True)\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "        ax.set_xlabel('Timesteps')\n",
    "        ax.grid(color='0.9', linestyle='-', linewidth=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "fig.tight_layout(rect=[0, 0, 1, .97])\n",
    "fig.patch.set_alpha(1)\n",
    "display(fig)\n",
    "plt.close()\n",
    "#plt.title(\"AGENTS VS THEIR POSITIVE ATTESTATIONS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.sort_values(by =['rules_price']).reset_index(drop=True)\n",
    "\n",
    "cols = 1\n",
    "rows = 1\n",
    "cc_idx = 0\n",
    "# config_labels = ['RULE 1,'RULE 2']\n",
    "\n",
    "\n",
    "while cc_idx<len(experiments):\n",
    "    cc = experiments.iloc[cc_idx]['rules_price']\n",
    "    cc_label = experiments.iloc[cc_idx]['rules_price']\n",
    "    sub_experiments = experiments[experiments['rules_price']==cc]\n",
    "    cc_idx += len(sub_experiments)\n",
    "    fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(15*cols,7*rows))\n",
    "    sub_experiments.reset_index(drop=False)\n",
    "    for i, experiment in sub_experiments.iterrows():\n",
    "        df = experiment['dataset'].copy()\n",
    "        # filter out starting point\n",
    "        df = df[df.timestep > 0] \n",
    "        # FIRST RUN ONLY\n",
    "        df = df[df.run == 1]  \n",
    "        \n",
    "\n",
    "# MAKE A FOR LOOP or FUNCTION FOR ALL AGENTS\n",
    "        df['agent_1_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][0]))\n",
    "        df['agent_2_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][1]))\n",
    "        df['agent_3_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][2]))\n",
    "        df['agent_4_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][3]))\n",
    "        df['agent_5_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][4]))\n",
    "        df['agent_6_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][5]))\n",
    "        df['agent_7_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][6]))\n",
    "        df['agent_8_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][7]))\n",
    "        df['agent_9_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][8]))\n",
    "        df['agent_10_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][9]))\n",
    "        df['agent_11_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][10]))\n",
    "        df['agent_12_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][11]))\n",
    "        df['agent_13_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][12]))\n",
    "        df['agent_14_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][13]))\n",
    "        df['agent_15_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][14]))\n",
    "        df['agent_16_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][15]))\n",
    "        df['agent_17_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][16]))\n",
    "        df['agent_18_attest_0'] = df.agents.apply(lambda x: np.array(x['agent_attestations_0'][17]))\n",
    "\n",
    "        plot_label = experiment['rules_price']\n",
    "        ax = axs\n",
    "        title = 'Agents vs their Negative Attestations' + '\\n' \n",
    "        # + 'Scenario: ' + str(cc_label)  + ' rules_price'\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel('Amount')\n",
    "        colors = ['b','orange', 'g', 'magenta', 'r']\n",
    "        \n",
    "\n",
    "        df.plot(x='timestep', y='agent_1_attest_0', label='agent_1', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_2_attest_0', label='agent_2', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_3_attest_0', label='agent_3', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_4_attest_0', label='agent_4', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_5_attest_0', label='agent_5', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_6_attest_0', label='agent_6', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_7_attest_0', label='agent_7', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_8_attest_0', label='agent_8', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_9_attest_0', label='agent_9', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_10_attest_0', label='agent_10', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_11_attest_0', label='agent_11', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_12_attest_0', label='agent_12', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_13_attest_0', label='agent_13', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_14_attest_0', label='agent_14', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_15_attest_0', label='agent_15', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_16_attest_0', label='agent_16', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_17_attest_0', label='agent_17', ax=ax, legend=True)\n",
    "        df.plot(x='timestep', y='agent_18_attest_0', label='agent_18', ax=ax, legend=True)\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "        ax.set_xlabel('Timesteps')\n",
    "        ax.grid(color='0.9', linestyle='-', linewidth=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "fig.tight_layout(rect=[0, 0, 1, .97])\n",
    "fig.patch.set_alpha(1)\n",
    "display(fig)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents' Belief of Alpha vs their Payout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "S_free = experiments.dataset[0].supply_free[t]\n",
    "S_0 = experiments.dataset[0].supply_0[t]\n",
    "S_1 = experiments.dataset[0].supply_1[t]\n",
    "\n",
    "agents_id = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "payout_list = []\n",
    "\n",
    "for a in agents_id:\n",
    "    #print(a)\n",
    "    q1 = experiments.dataset[0].agents[t].agent_attestations_1[a]\n",
    "    q0 = experiments.dataset[0].agents[t].agent_attestations_0[a]\n",
    "    \n",
    "    s_free = experiments.dataset[0].agents[t].agent_supply_free[a]\n",
    "    s1 = experiments.dataset[0].agents[t].agent_supply_1[a]\n",
    "    s0 = experiments.dataset[0].agents[t].agent_supply_0[a]\n",
    "    s = s_free + s1 + s0\n",
    "    \n",
    "    agent_private_alpha = experiments.dataset[0].agents[t].agent_private_alpha[a]\n",
    "\n",
    "    Q0 = experiments.dataset[0].attestations_0[t]\n",
    "    Q1 = experiments.dataset[0].attestations_1[t]\n",
    "\n",
    "    R = experiments.dataset[0].reserve[t]\n",
    "    S = experiments.dataset[0].supply[t]\n",
    "\n",
    "    C = experiments.C\n",
    "    alpha = experiments.dataset[0].alpha[t]\n",
    "\n",
    "    T1 = (s_free/s)*(alpha*C + R)\n",
    "    T2 = (s1/s)*(q1/Q1)*alpha*(C+R)\n",
    "    T3 = (s0/s)*(q0/Q0)*(1-alpha)*(R)\n",
    "\n",
    "    agent_payout = T1+T2+T3\n",
    "    payout_list.append(agent_payout)\n",
    "    #print(a, \"'s Payout = \", agent_payout, \"| Private Alpha = \", agent_private_alpha)\n",
    "\n",
    "#plt.plot(payout_list)\n",
    "\n",
    "arr2d = np.array(payout_list)\n",
    "\n",
    "arr1d = arr2d.flatten()\n",
    "\n",
    "x = agents_id\n",
    "payouts = arr1d\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "plt.bar(x_pos, payouts, color='green')\n",
    "plt.xlabel(\"Agent ID\")\n",
    "plt.ylabel(\"Payout amount (tokens)\")\n",
    "plt.title(\"Agent and their Payouts\")\n",
    "\n",
    "plt.xticks(x_pos, x)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that Agent 10 has the highest payout. <br>\n",
    "\n",
    "We know that Agent 10's private belief of Alpha is 0.50. To verify if this is close to the final system Alpha, we plot Alpha. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.sort_values(by =['rules_price']).reset_index(drop=True)\n",
    "\n",
    "cols = 1\n",
    "rows = 1\n",
    "cc_idx = 0\n",
    "\n",
    "\n",
    "while cc_idx<len(experiments):\n",
    "    cc = experiments.iloc[cc_idx]['rules_price']\n",
    "    cc_label = experiments.iloc[cc_idx]['rules_price']\n",
    "#     secondary_label = experiments.iloc[cc_idx]['string']\n",
    "    sub_experiments = experiments[experiments['rules_price']==cc]\n",
    "    cc_idx += len(sub_experiments)\n",
    "    fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(15*cols,7*rows))\n",
    "    sub_experiments.reset_index(drop=False)\n",
    "    for i, experiment in sub_experiments.iterrows():\n",
    "        df = experiment['dataset'].copy()\n",
    "        # filter out starting point\n",
    "        df = df[df.timestep > 0] \n",
    "        # FIRST RUN ONLY\n",
    "        df = df[df.run == 1]  \n",
    "\n",
    "# MAKE A FOR LOOP or FUNCTION FOR ALL AGENTS\n",
    "        chosen_agents = df['chosen_agent'].tolist()\n",
    "        chosen_agents_private_alphas = []\n",
    "        for agent in chosen_agents:\n",
    "            chosen_agents_private_alphas.append(agent['agent_private_alpha'])\n",
    "        \n",
    "        df['private_alpha'] = chosen_agents_private_alphas\n",
    "            \n",
    "        df['agent_1_private_alpha'] = df.agents.apply(lambda x: np.array(x['agent_private_alpha'][0]))\n",
    "        df['agent_2_private_alpha'] = df.agents.apply(lambda x: np.array(x['agent_private_alpha'][1]))\n",
    "        \n",
    "\n",
    "        plot_label = experiment['rules_price']\n",
    "        ax = axs\n",
    "        title = 'Agent Private Alpha vs Global Alpha' \n",
    "        # + '\\n' + 'Scenario: ' + str(cc_label)  + ' rules_price'\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel('Alpha Value')\n",
    "        colors = ['b','orange', 'g', 'magenta', 'r', 'k' ]\n",
    "        \n",
    "        #plt.hlines(y= max(df['agent_1_private_alpha']), xmin=0, xmax=max(df.timestep), label = 'Agent 1 Private Alpha',  color = colors[0])\n",
    "        #plt.hlines(y= max(df['agent_2_private_alpha']), xmin=0, xmax=max(df.timestep), label = 'Agent 2 Private Alpha',  color = colors[1])\n",
    "\n",
    "        df.plot(x='timestep', y='private_alpha', label='Private Alpha', ax=ax, legend=True, kind= 'scatter')\n",
    "        df.plot(x='timestep', y='alpha', label='Alpha', ax=ax, legend=True, color = colors[5])\n",
    "\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        ax.set_xlabel('Timesteps')\n",
    "        ax.grid(color='0.9', linestyle='-', linewidth=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "fig.tight_layout(rect=[0, 0, 1, .97])\n",
    "fig.patch.set_alpha(1)\n",
    "display(fig)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments.dataset[0].alpha[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system's final Alpha is 0.4977. <br/>\n",
    "Agent 10 with alpha belief 0.50 has the higest payout. \n",
    "\n",
    "Notice that jaggedness of the agent payout surface. It's not necessarily true that an agent with the closer belief of Alpha *always* and *strictly* gets a higher payout.\n",
    "\n",
    "Consider Agent 17 with a Alpha belief of 0.85 and a payout of 33.94. \n",
    "$$\\hat\\alpha_{17} = 0.85$$\n",
    "$$\\Theta_{17} = 33.94$$\n",
    "Agent 18 with an Alpha belief 0.9 - which is farther away from the final system Alpha -  obtained a much larger payout of 334.86.  \n",
    "$$\\hat\\alpha_{18} = 0.90$$\n",
    "$$\\Theta_{18} = 334.86$$\n",
    "\n",
    "This could be explained due to a possible large action that either agent took early on in the system when system Alpha was quite volatile. If said large action was in the right direction towards final system Alpha, this move acted in their advantage. If it was in the wrong direction to system Alpha, this resulted in their disadvantage. \n",
    "\n",
    "In this case, Agent 18 placed a risky bet towards the correct direction of system Alpha very early on. \n",
    "\n",
    "This indicates that the process has path dependence. This is a system property by design.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "The agent with the highest payout has an alpha belief of 0.50, which is close to the final system Alpha. We conclude that the agent with the closest prediction of Alpha generally obtains the largest final payout.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}